{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import censusdata\n",
    "import re\n",
    "import geopandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Funtions\n",
    "\n",
    "#Funcion For NonDigit Removing Characters from Row\n",
    "def remove_chars(s):\n",
    "    clean = int(re.sub('[^0-9]+', '', str(s))[-11:])\n",
    "    return clean\n",
    "\n",
    "#Function to get census data according to requirements\n",
    "def getcensustables(table):\n",
    "    tablename = 'data_' + table\n",
    "    print(tablename)\n",
    "    \n",
    "    # Set requirements to pull from Census API\n",
    "    \n",
    "    variablestopull = allvariablescsv.loc[allvariablescsv['Group']==table]['Name'].tolist()\n",
    "    #print(variablestopull)\n",
    "    \n",
    "    #variablestopull = variables['Name'].tolist()\n",
    "\n",
    "    #variablestopull = variables['Name'].tolist()\n",
    "    listofcounties = ['121', '089']\n",
    "    yearstopull = range(2012,2018,1)\n",
    "\n",
    "    #Pull Census Data according to requirement above\n",
    "    atlantadata = pd.DataFrame()\n",
    "\n",
    "    for year in yearstopull:\n",
    "        for county in listofcounties:\n",
    "\n",
    "            newdata = censusdata.download('acs5', year, censusdata.censusgeo([('state', '13'), ('county', county), ('tract', '*')]),variablestopull)\n",
    "            type(newdata)\n",
    "            newdata['YEAR'] = year\n",
    "            atlantadata = atlantadata.append(newdata)\n",
    "\n",
    "    #Rename Column Headings from Code to Text\n",
    "    for variable in variablestopull:\n",
    "        #print(variable)\n",
    "        renamevar1 = allvariablescsv.loc[allvariablescsv['Name']==variable]['Label'].iloc[0]\n",
    "        renamevar2 = allvariablescsv.loc[allvariablescsv['Name']==variable]['Concept'].iloc[0]\n",
    "        renamevar = renamevar2 + '_'+ renamevar1\n",
    "        #print(renamevar)\n",
    "        atlantadata = atlantadata.rename(columns={variable: renamevar})\n",
    "\n",
    "    #Transform Index to create GeoID\n",
    "\n",
    "\n",
    "    #Create GeoID Column\n",
    "    atlantadata['Name2'] = atlantadata.index\n",
    "    atlantadata['GEOID'] = atlantadata['Name2'].apply(remove_chars)\n",
    "    atlantadata.drop(columns=['Name2'], inplace=True)\n",
    "    \n",
    "    #Only Keep Atlanta Census Tracts(Geocodes)\n",
    "    finaldata = atlantageocodes.merge(atlantadata, how='left', on='GEOID')\n",
    "    \n",
    "    finaldata = finaldata.dropna(axis=0, how='any')\n",
    "    \n",
    "    return finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/tablestopull.csv' does not exist: b'data/tablestopull.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-4b74a9725ace>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Tables to Load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtablestoloadcsv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/tablestopull.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtablestoload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtablestoloadcsv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Tables'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda4\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda4\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda4\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda4\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda4\\envs\\PythonData\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/tablestopull.csv' does not exist: b'data/tablestopull.csv'"
     ]
    }
   ],
   "source": [
    "#Code Begins here\n",
    "\n",
    "#Tables to Load\n",
    "tablestoloadcsv = pd.read_csv('data/tablestopull.csv')\n",
    "tablestoload = tablestoloadcsv['Tables'].tolist()\n",
    "\n",
    "#Allvariables Table\n",
    "allvariablescsv = pd.read_csv('data/allvariables.csv')\n",
    "\n",
    "#Atlanta Geo Codes Table\n",
    "atlantageocodes = pd.read_csv('data/atlantageocodes.csv')\n",
    "\n",
    "#Create dictionary with each cleaned table as an entry\n",
    "alltables = dict()  \n",
    "\n",
    "for table in tablestoload:\n",
    "    data = getcensustables(table)\n",
    "    alltables[table] = data\n",
    "    \n",
    "    data.to_csv('data/' + table + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example Usage of Occupancy Over Time\n",
    "\n",
    "occupancytable = alltables['B25002']\n",
    "\n",
    "occupancytable = occupancytable.groupby('YEAR').sum()\n",
    "occupancytable['Percent_Occupied'] = (occupancytable['OCCUPANCY STATUS_Estimate!!Total!!Occupied'] / occupancytable['OCCUPANCY STATUS_Estimate!!Total'])*100 \n",
    "\n",
    "#print(occupancytable.head())\n",
    "\n",
    "occupancytable = occupancytable.reset_index()\n",
    "\n",
    "\n",
    "plt.plot(occupancytable['YEAR'], occupancytable['Percent_Occupied'])\n",
    "plt.title(\"Occupancy Over Time\", fontsize=18)\n",
    "plt.xlabel(\"Years\", fontsize=18)\n",
    "plt.ylabel(\"Occupancy %\", fontsize=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancytable = alltables['B25002']\n",
    "\n",
    "occupancytable['Percent_Occupied'] = (occupancytable['OCCUPANCY STATUS_Estimate!!Total!!Occupied'] / occupancytable['OCCUPANCY STATUS_Estimate!!Total'])*100 \n",
    "\n",
    "\n",
    "geotable = geopandas.read_file('tractdata/tl_2018_13_tract.shp')\n",
    "#geotable = geotable.astype('int64').dtypes\n",
    "geotable[['GEOID']] = geotable[['GEOID']].astype('int64')\n",
    "\n",
    "geotable2 = atlantageocodes.merge(geotable, how='left', on='GEOID')\n",
    "\n",
    "geotable2 = geotable.set_index('GEOID').join(occupancytable.set_index('GEOID'))\n",
    "\n",
    "geotable2 = geotable2.dropna(axis=0, how='any')\n",
    "\n",
    "geotable2.head()\n",
    "\n",
    "# set a variable that will call whatever column we want to visualise on the map\n",
    "variable = 'Percent_Occupied'\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = 120, 220\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "# create map\n",
    "geotable2.plot(column=variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "plt.title(\"Occupancy Rate By Area\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancytable = alltables['B25002']\n",
    "\n",
    "occupancytable['Percent_Occupied'] = (occupancytable['OCCUPANCY STATUS_Estimate!!Total!!Occupied'] / occupancytable['OCCUPANCY STATUS_Estimate!!Total'])*100 \n",
    "\n",
    "\n",
    "geotable = geopandas.read_file('tractdata/tl_2018_13_tract.shp')\n",
    "#geotable = geotable.astype('int64').dtypes\n",
    "geotable[['GEOID']] = geotable[['GEOID']].astype('int64')\n",
    "\n",
    "geotable2 = atlantageocodes.merge(geotable, how='left', on='GEOID')\n",
    "\n",
    "geotable2 = geotable.set_index('GEOID').join(occupancytable.set_index('GEOID'))\n",
    "\n",
    "geotable2 = geotable2.dropna(axis=0, how='any')\n",
    "\n",
    "geotable2.head()\n",
    "\n",
    "# set a variable that will call whatever column we want to visualise on the map\n",
    "variable = 'Percent_Occupied'\n",
    "# set the range for the choropleth\n",
    "vmin, vmax = 120, 220\n",
    "# create figure and axes for Matplotlib\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "\n",
    "# create map\n",
    "geotable2.plot(column=variable, cmap='Blues', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "plt.title(\"Occupancy Rate By Area\", fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 36 (PythonData)",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
